{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Set  up  accounts and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sagemaker==1.39.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "account_id =  boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "\n",
    "#role = sagemaker.get_execution_role()\n",
    "role=\"arn:aws:iam::{}:role/service-role/AmazonSageMaker-ExecutionRole-20190118T115449\".format(account_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Setup image and instance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_custom_image_name=\"ppi-extractor:gpu-1.0.0-201910130520\"\n",
    "instance_type = \"ml.p3.8xlarge\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_repo = \"{}.dkr.ecr.{}.amazonaws.com/{}\".format(account_id, region, pytorch_custom_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Configure train/ test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"aegovan-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainfile = \"s3://{}/aimed/AIMedtrain.json\".format(bucket)\n",
    "#trainfile = \"s3://{}/aimed/AIMedFull.json\".format(bucket)\n",
    "trainfile=\"s3://{}/aimed/AIMedFull_preprocessed.json\".format(bucket)\n",
    "\n",
    "valfile=\"s3://{}/aimed/AIMedval_preprocessed.json\".format(bucket)\n",
    "# trainfile = \"s3://{}/aimed/AIMedtrain_pubmedoverlap.json\".format(bucket)\n",
    "# valfile=\"s3://{}/aimed/AIMedval_pubmedoverlap.json\".format(bucket)\n",
    "#embeddingfile=\"s3://{}/embeddings/PubMed-and-PMC-w2v.bin.txt\".format(bucket)\n",
    "#embeddingfile=\"s3://{}/embeddings/bio_nlp_vec/PubMed-shuffle-win-30.bin.txt\".format(bucket)\n",
    "pretrained_bert=\"s3://{}/embeddings/bert/\".format(bucket)\n",
    "\n",
    "\n",
    "s3_output_path= \"s3://{}/results/\".format(bucket)\n",
    "s3_code_path= \"s3://{}/aimed_bert_code\".format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_inputs = {\n",
    "    \"train\" : trainfile,\n",
    "    \"PRETRAINED_BIOBERT\" : pretrained_bert\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertNetworkFactoryhyperparameters = {\n",
    "  #  \"dataset\":\"PpiAimedDatasetFactory\",\n",
    "    \"dataset\":\"PpiAimedDatasetPreprocessedFactory\",\n",
    "    \"network\" :\"RelationExtractorBioBertFactory\",\n",
    "    \"trainfile\":trainfile.split(\"/\")[-1],\n",
    "    \"batchsize\": \"8\",\n",
    "    \"accumulation_steps\" : \"4\",\n",
    "    \"epochs\" : \"1000\",   \n",
    "    \"log-level\" : \"INFO\",\n",
    "    \"learningrate\":.00001,\n",
    "    \"earlystoppingpatience\":20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [{\"Name\": \"TrainLoss\",\n",
    "                     \"Regex\": \"###score: train_loss### (\\d*[.]?\\d*)\"}\n",
    "                    ,{\"Name\": \"ValidationLoss\",\n",
    "                     \"Regex\": \"###score: val_loss### (\\d*[.]?\\d*)\"}\n",
    "                    ,{\"Name\": \"TrainFScore\",\n",
    "                     \"Regex\": \"###score: train_fscore### (\\d*[.]?\\d*)\"}\n",
    "                   ,{\"Name\": \"ValidationFScore\",\n",
    "                     \"Regex\": \"###score: val_fscore### (\\d*[.]?\\d*)\"}\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commit 0cc8fdd48eb7813e65179a3d325079b95fd0ae8b\n",
      "    fix typo\n"
     ]
    }
   ],
   "source": [
    "!git log -1 | head -1\n",
    "!git log -1 | head -5 | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_config = {'repo': 'https://github.com/elangovana/PPI-typed-relation-extractor.git',\n",
    "              'branch': 'master',\n",
    "            #  'commit': '58a09e154935248667062a36fdae7d86b86b477c'\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = BertNetworkFactoryhyperparameters\n",
    "inputs = pub_inputs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accumulation_steps': '4',\n",
       " 'batchsize': '8',\n",
       " 'dataset': 'PpiAimedDatasetPreprocessedFactory',\n",
       " 'earlystoppingpatience': 20,\n",
       " 'epochs': '1000',\n",
       " 'learningrate': 1e-05,\n",
       " 'log-level': 'INFO',\n",
       " 'network': 'RelationExtractorBioBertFactory',\n",
       " 'trainfile': 'AIMedFull_preprocessed.json'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PRETRAINED_BIOBERT': 's3://aegovan-data/embeddings/bert/',\n",
       " 'train': 's3://aegovan-data/aimed/AIMedFull_preprocessed.json'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "     #entry_point='main_train_k_fold.py',\n",
    "    entry_point='main_train_bert_k_fold.py',\n",
    "                    source_dir = 'source/algorithms',\n",
    "                    dependencies =['source/algorithms', 'source/datasets', 'source/preprocessor', 'source/modelnetworks','source/trainpipelinesbuilders'],\n",
    "                    role=role,\n",
    "                    framework_version =\"1.0.0\",\n",
    "                    py_version='py3',\n",
    "                    git_config= git_config,\n",
    "                    image_name= docker_repo,\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type=instance_type,\n",
    "                    hyperparameters =hyperparameters,\n",
    "                    output_path=s3_output_path,\n",
    "                    metric_definitions=metric_definitions,\n",
    "                    #train_use_spot_instances = True\n",
    "                    train_volume_size=30,\n",
    "                    code_location=s3_code_path,\n",
    "                    train_max_run = 60 * 60 * 24 * 4,\n",
    "                    base_job_name =\"aimed-ppi-bert-acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-27 06:44:43 Starting - Starting the training job...\n",
      "2019-10-27 06:44:47 Starting - Launching requested ML instances...\n",
      "2019-10-27 06:45:44 Starting - Preparing the instances for training......\n",
      "2019-10-27 06:47:01 Downloading - Downloading input data\n",
      "2019-10-27 06:47:01 Training - Downloading the training image..........\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:03,691 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:03,736 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:06,753 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:07,088 sagemaker-containers INFO     Module main_train_bert_k_fold does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:07,088 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:07,088 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:07,088 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: main-train-bert-k-fold\n",
      "  Running setup.py bdist_wheel for main-train-bert-k-fold: started\u001b[0m\n",
      "\u001b[31m  Running setup.py bdist_wheel for main-train-bert-k-fold: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-e7_zxlr6/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built main-train-bert-k-fold\u001b[0m\n",
      "\u001b[31mInstalling collected packages: main-train-bert-k-fold\u001b[0m\n",
      "\u001b[31mSuccessfully installed main-train-bert-k-fold-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.3.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:09,658 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"PRETRAINED_BIOBERT\": \"/opt/ml/input/data/PRETRAINED_BIOBERT\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"learningrate\": 1e-05,\n",
      "        \"trainfile\": \"AIMedFull_preprocessed.json\",\n",
      "        \"batchsize\": \"8\",\n",
      "        \"accumulation_steps\": \"4\",\n",
      "        \"network\": \"RelationExtractorBioBertFactory\",\n",
      "        \"log-level\": \"INFO\",\n",
      "        \"dataset\": \"PpiAimedDatasetPreprocessedFactory\",\n",
      "        \"epochs\": \"1000\",\n",
      "        \"earlystoppingpatience\": 20\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"PRETRAINED_BIOBERT\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"aimed-ppi-bert-acc-2019-10-27-06-44-16-493\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://aegovan-data/aimed_bert_code/aimed-ppi-bert-acc-2019-10-27-06-44-16-493/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"main_train_bert_k_fold\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"main_train_bert_k_fold.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"accumulation_steps\":\"4\",\"batchsize\":\"8\",\"dataset\":\"PpiAimedDatasetPreprocessedFactory\",\"earlystoppingpatience\":20,\"epochs\":\"1000\",\"learningrate\":1e-05,\"log-level\":\"INFO\",\"network\":\"RelationExtractorBioBertFactory\",\"trainfile\":\"AIMedFull_preprocessed.json\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=main_train_bert_k_fold.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"PRETRAINED_BIOBERT\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"PRETRAINED_BIOBERT\",\"train\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=main_train_bert_k_fold\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://aegovan-data/aimed_bert_code/aimed-ppi-bert-acc-2019-10-27-06-44-16-493/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"PRETRAINED_BIOBERT\":\"/opt/ml/input/data/PRETRAINED_BIOBERT\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"accumulation_steps\":\"4\",\"batchsize\":\"8\",\"dataset\":\"PpiAimedDatasetPreprocessedFactory\",\"earlystoppingpatience\":20,\"epochs\":\"1000\",\"learningrate\":1e-05,\"log-level\":\"INFO\",\"network\":\"RelationExtractorBioBertFactory\",\"trainfile\":\"AIMedFull_preprocessed.json\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"PRETRAINED_BIOBERT\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"aimed-ppi-bert-acc-2019-10-27-06-44-16-493\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://aegovan-data/aimed_bert_code/aimed-ppi-bert-acc-2019-10-27-06-44-16-493/source/sourcedir.tar.gz\",\"module_name\":\"main_train_bert_k_fold\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"main_train_bert_k_fold.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--accumulation_steps\",\"4\",\"--batchsize\",\"8\",\"--dataset\",\"PpiAimedDatasetPreprocessedFactory\",\"--earlystoppingpatience\",\"20\",\"--epochs\",\"1000\",\"--learningrate\",\"1e-05\",\"--log-level\",\"INFO\",\"--network\",\"RelationExtractorBioBertFactory\",\"--trainfile\",\"AIMedFull_preprocessed.json\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_PRETRAINED_BIOBERT=/opt/ml/input/data/PRETRAINED_BIOBERT\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HP_LEARNINGRATE=1e-05\u001b[0m\n",
      "\u001b[31mSM_HP_TRAINFILE=AIMedFull_preprocessed.json\u001b[0m\n",
      "\u001b[31mSM_HP_BATCHSIZE=8\u001b[0m\n",
      "\u001b[31mSM_HP_ACCUMULATION_STEPS=4\u001b[0m\n",
      "\u001b[31mSM_HP_NETWORK=RelationExtractorBioBertFactory\u001b[0m\n",
      "\u001b[31mSM_HP_LOG-LEVEL=INFO\u001b[0m\n",
      "\u001b[31mSM_HP_DATASET=PpiAimedDatasetPreprocessedFactory\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=1000\u001b[0m\n",
      "\u001b[31mSM_HP_EARLYSTOPPINGPATIENCE=20\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m main_train_bert_k_fold --accumulation_steps 4 --batchsize 8 --dataset PpiAimedDatasetPreprocessedFactory --earlystoppingpatience 20 --epochs 1000 --learningrate 1e-05 --log-level INFO --network RelationExtractorBioBertFactory --trainfile AIMedFull_preprocessed.json\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m['--accumulation_steps', '4', '--batchsize', '8', '--learningrate', '1e-05']\u001b[0m\n",
      "\u001b[31m{'dataset': 'PpiAimedDatasetPreprocessedFactory', 'network': 'RelationExtractorBioBertFactory', 'trainfile': 'AIMedFull_preprocessed.json', 'traindir': '/opt/ml/input/data/train', 'pretrained_biobert_dir': '/opt/ml/input/data/PRETRAINED_BIOBERT', 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'epochs': 1000, 'earlystoppingpatience': 20, 'interaction_type': None, 'log_level': 'INFO'}\u001b[0m\n",
      "\u001b[31m{'accumulation_steps': '4', 'batchsize': '8', 'learningrate': '1e-05'}\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:12,075 - __main__ - INFO - Running fold 0\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:12,104 - trainpipelinesbuilders.BertTrainInferenceBuilder - INFO - Retrieving key batchsize with default 32, found 8\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:12,104 - trainpipelinesbuilders.BertTrainInferenceBuilder - INFO - Retrieving key pretrained_biobert_dir with default None, found /opt/ml/input/data/PRETRAINED_BIOBERT\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:12,104 - pytorch_pretrained_bert.tokenization - INFO - loading vocabulary file /opt/ml/input/data/PRETRAINED_BIOBERT/vocab.txt\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:12,158 - pytorch_pretrained_bert.tokenization - INFO - loading vocabulary file /opt/ml/input/data/PRETRAINED_BIOBERT/vocab.txt\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:12,202 - modelnetworks.RelationExtractorBioBertFactory - INFO - Retrieving key pretrained_biobert_dir with default None, found /opt/ml/input/data/PRETRAINED_BIOBERT\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:12,203 - pytorch_pretrained_bert.modeling - INFO - loading archive file /opt/ml/input/data/PRETRAINED_BIOBERT\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:12,204 - pytorch_pretrained_bert.modeling - INFO - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:17,278 - pytorch_pretrained_bert.modeling - INFO - Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:17,278 - pytorch_pretrained_bert.modeling - INFO - Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\u001b[0m\n",
      "\u001b[31mBertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): BertLayerNorm()\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\u001b[0m\n",
      "\u001b[31m)\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:17,280 - trainpipelinesbuilders.BertTrainInferenceBuilder - INFO - Using model <class 'modelnetworks.RelationExtractorBioBert.RelationExtractorBioBert'>\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:17,281 - trainpipelinesbuilders.BertTrainInferenceBuilder - INFO - \u001b[0m\n",
      "\u001b[31mRelationExtractorBioBert(\n",
      "  (model): BertForSequenceClassification(\n",
      "    (bert): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): BertLayerNorm()\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1)\n",
      "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  )\u001b[0m\n",
      "\u001b[31m)\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:17,281 - trainpipelinesbuilders.BertTrainInferenceBuilder - INFO - Using loss function <class 'torch.nn.modules.loss.CrossEntropyLoss'>\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:17,281 - trainpipelinesbuilders.BertTrainInferenceBuilder - INFO - Retrieving key accumulation_steps with default 1, found 4\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:17,449 - algorithms.BertTrainInferencePipeline - INFO - Train set has 5250 records, val has 584\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:17,449 - algorithms.transform_berttext_tokenise - INFO - Transforming TransformBertTextTokenise\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:21,450 - algorithms.transform_berttext_tokenise - INFO - Completed TransformBertTextTokenise\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:21,451 - algorithms.transform_berttext_token_to_index - INFO - Transforming TransformBertTextTokenToIndex\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2019-10-27 06:49:21,935 - algorithms.transform_berttext_token_to_index - INFO - Completed TransformBertTextTokenToIndex\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:21,946 - algorithms.transform_berttext_tokenise - INFO - Transforming TransformBertTextTokenise\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:22,478 - algorithms.transform_berttext_tokenise - INFO - Completed TransformBertTextTokenise\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:22,478 - algorithms.transform_berttext_token_to_index - INFO - Transforming TransformBertTextTokenToIndex\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:22,532 - algorithms.transform_berttext_token_to_index - INFO - Completed TransformBertTextTokenToIndex\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:22,534 - algorithms.transform_label_encoder - INFO - Running TransformLabelEncoder\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:22,535 - algorithms.transform_label_encoder - INFO - Complete TransformLabelEncoder\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:22,580 - algorithms.BertTrainInferencePipeline - INFO - Retrieving key learningrate with default .01, found 1e-05\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:22,581 - algorithms.BertTrainInferencePipeline - INFO - Retrieving key weight_decay with default .0001, found .0001\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:22,581 - pytorch_pretrained_bert.optimization - WARNING - t_total value of -1 results in schedule not being applied\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:22,582 - algorithms.BertTrainInferencePipeline - INFO - Using optimiser <class 'pytorch_pretrained_bert.optimization.BertAdam'>\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:22,582 - algorithms.transform_label_rehaper - INFO - Loading int 1 to tensor 1\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:22,582 - algorithms.BertTrainInferencePipeline - INFO - Positive label True is 1\u001b[0m\n",
      "\u001b[31m2019-10-27 06:49:22,609 - algorithms.BertTrain - INFO - using score : <class 'algorithms.result_scorer_f1.ResultScorerF1'>\u001b[0m\n",
      "\n",
      "2019-10-27 06:49:02 Training - Training image download completed. Training in progress.\u001b[31m2019-10-27 06:53:44,501 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 06:53:44,511 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_9c65519e-db05-4c07-a625-48dcaedf2222_20191027_065344.csv: \u001b[0m\n",
      "\u001b[31m[[4339    0]\n",
      " [ 911    0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 06:53:44,520 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 06:53:44,520 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 06:53:51,287 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_e3b07f8a-19e4-4ef1-b68e-9dd4437ba974_20191027_065351.csv: \u001b[0m\n",
      "\u001b[31m[[495   0]\n",
      " [ 89   0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 06:53:51,289 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-27 06:53:51,289 - algorithms.BertTrain - INFO - Snapshotting because the current score 0.0 is greater than None \u001b[0m\n",
      "\u001b[31m2019-10-27 06:53:51,289 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/model/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 06:53:51,740 - algorithms.BertTrain - INFO - Run    269     0       657     3/657         0% 305.179160 31.178821       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 305.179159745574\u001b[0m\n",
      "\u001b[31m###score: val_loss### 31.178821459412575\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 06:58:09,291 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 06:58:09,298 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_e20d4f01-d8bc-43a4-9269-25c3d9cb90ea_20191027_065809.csv: \u001b[0m\n",
      "\u001b[31m[[4339    0]\n",
      " [ 911    0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 06:58:09,305 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 06:58:09,305 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 06:58:16,061 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_715daf4e-43b9-42b7-bb54-57f40c157c2c_20191027_065816.csv: \u001b[0m\n",
      "\u001b[31m[[495   0]\n",
      " [ 89   0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 06:58:16,063 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-27 06:58:16,063 - algorithms.BertTrain - INFO - Snapshotting because the current loss 31.166553765535355 is lower than 31.178821459412575 \u001b[0m\n",
      "\u001b[31m2019-10-27 06:58:16,063 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/output/data/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 06:58:16,479 - algorithms.BertTrain - INFO - Run    533     1      1314     3/657         0% 304.738309 31.166554       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 304.7383085936308\u001b[0m\n",
      "\u001b[31m###score: val_loss### 31.166553765535355\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 07:02:33,825 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:02:33,833 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_a179343f-ac5d-4ddb-9beb-296969bb2a47_20191027_070233.csv: \u001b[0m\n",
      "\u001b[31m[[4339    0]\n",
      " [ 911    0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:02:33,839 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 07:02:33,839 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:02:40,593 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_c8a57c67-c201-47f5-a913-ca3945a17b21_20191027_070240.csv: \u001b[0m\n",
      "\u001b[31m[[495   0]\n",
      " [ 89   0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:02:40,595 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:02:40,595 - algorithms.BertTrain - INFO - Snapshotting because the current loss 31.158877342939377 is lower than 31.166553765535355 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:02:40,595 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/output/data/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 07:02:41,120 - algorithms.BertTrain - INFO - Run    798     2      1971     3/657         0% 303.568355 31.158877       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 303.5683551877737\u001b[0m\n",
      "\u001b[31m###score: val_loss### 31.158877342939377\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 07:06:58,441 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:06:58,449 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_296c1740-ad6c-471b-baed-29d98aa7c31e_20191027_070658.csv: \u001b[0m\n",
      "\u001b[31m[[4339    0]\n",
      " [ 911    0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:06:58,455 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 07:06:58,455 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:07:05,213 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_b73a53f8-b4a2-48c9-b37d-56e84dbc0f32_20191027_070705.csv: \u001b[0m\n",
      "\u001b[31m[[495   0]\n",
      " [ 89   0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:07:05,214 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:07:05,214 - algorithms.BertTrain - INFO - Snapshotting because the current loss 31.1331719905138 is lower than 31.158877342939377 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:07:05,215 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/output/data/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 07:07:05,738 - algorithms.BertTrain - INFO - Run   1063     3      2628     3/657         0% 303.633105 31.133172       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 303.63310457766056\u001b[0m\n",
      "\u001b[31m###score: val_loss### 31.1331719905138\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 07:11:23,510 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:11:23,517 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_539050c8-8d5e-464e-85c8-92a175597b40_20191027_071123.csv: \u001b[0m\n",
      "\u001b[31m[[4339    0]\n",
      " [ 911    0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:11:23,524 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 07:11:23,524 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2019-10-27 07:11:30,295 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_0507779c-2382-4b63-a23a-ca9b0d8f1ea0_20191027_071130.csv: \u001b[0m\n",
      "\u001b[31m[[495   0]\n",
      " [ 89   0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:11:30,297 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:11:30,297 - algorithms.BertTrain - INFO - Snapshotting because the current loss 30.32103531807661 is lower than 31.1331719905138 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:11:30,297 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/output/data/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 07:11:30,828 - algorithms.BertTrain - INFO - Run   1328     4      3285     3/657         0% 298.852976 30.321035       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 298.85297636687756\u001b[0m\n",
      "\u001b[31m###score: val_loss### 30.32103531807661\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 07:15:48,795 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:15:48,802 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_ea395012-5032-4135-9457-ddb48848b4e4_20191027_071548.csv: \u001b[0m\n",
      "\u001b[31m[[4339    0]\n",
      " [ 911    0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:15:48,809 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 07:15:48,809 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:15:55,577 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_e8038fde-d563-4199-ab92-a7a7d696bddb_20191027_071555.csv: \u001b[0m\n",
      "\u001b[31m[[495   0]\n",
      " [ 89   0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:15:55,578 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:15:55,579 - algorithms.BertTrain - INFO - Snapshotting because the current loss 30.024198293685913 is lower than 30.32103531807661 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:15:55,579 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/output/data/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 07:15:56,104 - algorithms.BertTrain - INFO - Run   1593     5      3942     3/657         0% 293.703016 30.024198       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 293.70301555097103\u001b[0m\n",
      "\u001b[31m###score: val_loss### 30.024198293685913\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 07:20:13,431 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:20:13,439 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_c850df32-9003-4349-b8db-cd23b9de7fb8_20191027_072013.csv: \u001b[0m\n",
      "\u001b[31m[[4339    0]\n",
      " [ 911    0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:20:13,445 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 07:20:13,445 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:20:20,215 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_e0fdd49a-0dd6-45f3-979d-a3c7509a7adf_20191027_072020.csv: \u001b[0m\n",
      "\u001b[31m[[495   0]\n",
      " [ 89   0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:20:20,217 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:20:20,217 - algorithms.BertTrain - INFO - Run   1857     6      4599     3/657         0% 291.794707 30.427502       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 291.7947074100375\u001b[0m\n",
      "\u001b[31m###score: val_loss### 30.42750233411789\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 07:24:37,987 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:24:37,995 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_198d1a0c-e959-4652-b2f5-c49f9e2cbe2a_20191027_072437.csv: \u001b[0m\n",
      "\u001b[31m[[4339    0]\n",
      " [ 911    0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:24:38,001 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 07:24:38,001 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:24:44,771 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_f67ccab9-bb78-40ea-bdd8-828c3f8bed90_20191027_072444.csv: \u001b[0m\n",
      "\u001b[31m[[495   0]\n",
      " [ 89   0]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:24:44,773 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:24:44,773 - algorithms.BertTrain - INFO - Snapshotting because the current loss 29.803310871124268 is lower than 30.024198293685913 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:24:44,773 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/output/data/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 07:24:45,293 - algorithms.BertTrain - INFO - Run   2122     7      5256     3/657         0% 262.291992 29.803311       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 262.2919923886657\u001b[0m\n",
      "\u001b[31m###score: val_loss### 29.803310871124268\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-27 07:29:03,112 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:29:03,120 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_62dc1017-e54b-459b-80a1-aa06761a1a3d_20191027_072903.csv: \u001b[0m\n",
      "\u001b[31m[[3854  485]\n",
      " [ 492  419]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:29:03,127 - algorithms.BertTrain - INFO - Train set result details: 0.46170798898071624\u001b[0m\n",
      "\u001b[31m2019-10-27 07:29:03,127 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:29:09,899 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_39aa48e0-770c-4433-91ab-7e8cd87f9ff9_20191027_072909.csv: \u001b[0m\n",
      "\u001b[31m[[428  67]\n",
      " [ 58  31]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:29:09,901 - algorithms.BertTrain - INFO - Validation set result details: 0.3315508021390375 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:29:09,901 - algorithms.BertTrain - INFO - Snapshotting because the current score 0.3315508021390375 is greater than 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:29:09,901 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/model/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 07:29:10,435 - algorithms.BertTrain - INFO - Run   2387     8      5913     3/657         0% 243.913892 30.721818       0.4617       0.3316\u001b[0m\n",
      "\u001b[31m###score: train_loss### 243.9138922393322\u001b[0m\n",
      "\u001b[31m###score: val_loss### 30.72181825339794\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.46170798898071624\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.3315508021390375\u001b[0m\n",
      "\u001b[31m2019-10-27 07:33:28,121 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:33:28,129 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_996bc831-63a6-44bb-83a7-d6da6c9b8f6c_20191027_073328.csv: \u001b[0m\n",
      "\u001b[31m[[4019  320]\n",
      " [ 516  395]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:33:28,136 - algorithms.BertTrain - INFO - Train set result details: 0.4858548585485855\u001b[0m\n",
      "\u001b[31m2019-10-27 07:33:28,136 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:33:34,899 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_be4be8c2-1f32-4d8b-8ae2-b32bef43d6af_20191027_073334.csv: \u001b[0m\n",
      "\u001b[31m[[446  49]\n",
      " [ 63  26]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:33:34,901 - algorithms.BertTrain - INFO - Validation set result details: 0.3170731707317073 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:33:34,901 - algorithms.BertTrain - INFO - Run   2652     9      6570     3/657         0% 236.557992 30.166360       0.4859       0.3171\u001b[0m\n",
      "\u001b[31m###score: train_loss### 236.5579921901226\u001b[0m\n",
      "\u001b[31m###score: val_loss### 30.166359551250935\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.4858548585485855\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.3170731707317073\u001b[0m\n",
      "\u001b[31m2019-10-27 07:37:52,535 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:37:52,543 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_5135c0a5-6d69-436b-9722-3b706d4fe7b4_20191027_073752.csv: \u001b[0m\n",
      "\u001b[31m[[4103  236]\n",
      " [ 461  450]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:37:52,550 - algorithms.BertTrain - INFO - Train set result details: 0.5635566687539136\u001b[0m\n",
      "\u001b[31m2019-10-27 07:37:52,550 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2019-10-27 07:37:59,318 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_e8a084a9-9895-4b9a-b77d-0308a7c79dd2_20191027_073759.csv: \u001b[0m\n",
      "\u001b[31m[[452  43]\n",
      " [ 64  25]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:37:59,320 - algorithms.BertTrain - INFO - Validation set result details: 0.3184713375796179 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:37:59,320 - algorithms.BertTrain - INFO - Run   2916    10      7227     3/657         0% 218.178351 30.279408       0.5636       0.3185\u001b[0m\n",
      "\u001b[31m###score: train_loss### 218.17835077643394\u001b[0m\n",
      "\u001b[31m###score: val_loss### 30.2794082313776\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.5635566687539136\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.3184713375796179\u001b[0m\n",
      "\u001b[31m2019-10-27 07:42:17,557 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:42:17,565 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_9257c436-50e2-4531-a359-4375cd6c3740_20191027_074217.csv: \u001b[0m\n",
      "\u001b[31m[[4236  103]\n",
      " [ 487  424]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:42:17,572 - algorithms.BertTrain - INFO - Train set result details: 0.5897079276773297\u001b[0m\n",
      "\u001b[31m2019-10-27 07:42:17,572 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:42:24,348 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_fdf13900-505f-45f1-95bf-01925b302f42_20191027_074224.csv: \u001b[0m\n",
      "\u001b[31m[[472  23]\n",
      " [ 60  29]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:42:24,350 - algorithms.BertTrain - INFO - Validation set result details: 0.4113475177304965 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:42:24,350 - algorithms.BertTrain - INFO - Snapshotting because the current score 0.4113475177304965 is greater than 0.3315508021390375 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:42:24,350 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/model/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 07:42:24,880 - algorithms.BertTrain - INFO - Run   3182    11      7884     3/657         0% 187.021106 25.787089       0.5897       0.4113\u001b[0m\n",
      "\u001b[31m###score: train_loss### 187.02110615372658\u001b[0m\n",
      "\u001b[31m###score: val_loss### 25.787088744342327\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.5897079276773297\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.4113475177304965\u001b[0m\n",
      "\u001b[31m2019-10-27 07:46:42,627 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:46:42,634 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_44e92da8-c581-4e80-92f9-3867204efef4_20191027_074642.csv: \u001b[0m\n",
      "\u001b[31m[[4251   88]\n",
      " [ 456  455]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:46:42,641 - algorithms.BertTrain - INFO - Train set result details: 0.62585969738652\u001b[0m\n",
      "\u001b[31m2019-10-27 07:46:42,641 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:46:49,409 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_e28ff163-2998-4e74-b8a1-579d4bbe2666_20191027_074649.csv: \u001b[0m\n",
      "\u001b[31m[[470  25]\n",
      " [ 58  31]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:46:49,411 - algorithms.BertTrain - INFO - Validation set result details: 0.4275862068965518 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:46:49,411 - algorithms.BertTrain - INFO - Snapshotting because the current score 0.4275862068965518 is greater than 0.4113475177304965 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:46:49,411 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/model/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 07:46:49,924 - algorithms.BertTrain - INFO - Run   3447    12      8541     3/657         0% 176.329533 27.174895       0.6259       0.4276\u001b[0m\n",
      "\u001b[31m###score: train_loss### 176.32953292131424\u001b[0m\n",
      "\u001b[31m###score: val_loss### 27.174894623458385\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.62585969738652\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.4275862068965518\u001b[0m\n",
      "\u001b[31m2019-10-27 07:51:07,442 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:51:07,449 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_92802047-4738-478e-8fa0-c3866a32eeb8_20191027_075107.csv: \u001b[0m\n",
      "\u001b[31m[[4229  110]\n",
      " [ 319  592]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:51:07,456 - algorithms.BertTrain - INFO - Train set result details: 0.7340359578425294\u001b[0m\n",
      "\u001b[31m2019-10-27 07:51:07,456 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:51:14,223 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_52665f57-6127-4b14-866a-1a424a93104e_20191027_075114.csv: \u001b[0m\n",
      "\u001b[31m[[471  24]\n",
      " [ 46  43]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:51:14,225 - algorithms.BertTrain - INFO - Validation set result details: 0.5512820512820513 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:51:14,225 - algorithms.BertTrain - INFO - Snapshotting because the current score 0.5512820512820513 is greater than 0.4275862068965518 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:51:14,225 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/model/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 07:51:14,750 - algorithms.BertTrain - INFO - Run   3712    13      9198     3/657         0% 149.310833 26.804607       0.7340       0.5513\u001b[0m\n",
      "\u001b[31m###score: train_loss### 149.31083331629634\u001b[0m\n",
      "\u001b[31m###score: val_loss### 26.80460722744465\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.7340359578425294\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.5512820512820513\u001b[0m\n",
      "\u001b[31m2019-10-27 07:55:32,342 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:55:32,350 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_39eac508-caf1-4b38-8012-162036bbd461_20191027_075532.csv: \u001b[0m\n",
      "\u001b[31m[[4291   48]\n",
      " [ 425  486]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:55:32,356 - algorithms.BertTrain - INFO - Train set result details: 0.6726643598615917\u001b[0m\n",
      "\u001b[31m2019-10-27 07:55:32,357 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:55:39,125 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_8eda5cf5-b672-4d5a-a728-2bb83ab69d63_20191027_075539.csv: \u001b[0m\n",
      "\u001b[31m[[480  15]\n",
      " [ 55  34]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:55:39,127 - algorithms.BertTrain - INFO - Validation set result details: 0.4927536231884058 \u001b[0m\n",
      "\u001b[31m2019-10-27 07:55:39,127 - algorithms.BertTrain - INFO - Run   3976    14      9855     3/657         0% 148.650532 26.202925       0.6727       0.4928\u001b[0m\n",
      "\u001b[31m###score: train_loss### 148.65053232386708\u001b[0m\n",
      "\u001b[31m###score: val_loss### 26.202925227582455\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.6726643598615917\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.4927536231884058\u001b[0m\n",
      "\u001b[31m2019-10-27 07:59:56,757 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 07:59:56,765 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_bafcd560-3029-4c83-a2d5-093c70131216_20191027_075956.csv: \u001b[0m\n",
      "\u001b[31m[[4285   54]\n",
      " [ 342  569]]\u001b[0m\n",
      "\u001b[31m2019-10-27 07:59:56,772 - algorithms.BertTrain - INFO - Train set result details: 0.741851368970013\u001b[0m\n",
      "\u001b[31m2019-10-27 07:59:56,772 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:00:03,544 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_a6060a14-c508-499b-9b8b-31db1420c485_20191027_080003.csv: \u001b[0m\n",
      "\u001b[31m[[481  14]\n",
      " [ 54  35]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:00:03,546 - algorithms.BertTrain - INFO - Validation set result details: 0.5072463768115942 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:00:03,546 - algorithms.BertTrain - INFO - Run   4240    15     10512     3/657         0% 122.975556 26.905260       0.7419       0.5072\u001b[0m\n",
      "\u001b[31m###score: train_loss### 122.97555566206574\u001b[0m\n",
      "\u001b[31m###score: val_loss### 26.90526032075286\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.741851368970013\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.5072463768115942\u001b[0m\n",
      "\u001b[31m2019-10-27 08:04:21,101 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:04:21,109 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_ed2ef1f3-c5b4-4725-8aab-492a84bd81ee_20191027_080421.csv: \u001b[0m\n",
      "\u001b[31m[[4271   68]\n",
      " [ 210  701]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:04:21,116 - algorithms.BertTrain - INFO - Train set result details: 0.8345238095238094\u001b[0m\n",
      "\u001b[31m2019-10-27 08:04:21,116 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:04:27,888 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_9e61b4d0-990a-465d-b315-0c439dce7216_20191027_080427.csv: \u001b[0m\n",
      "\u001b[31m[[465  30]\n",
      " [ 44  45]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:04:27,890 - algorithms.BertTrain - INFO - Validation set result details: 0.5487804878048781 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:04:27,890 - algorithms.BertTrain - INFO - Run   4505    16     11169     3/657         0% 96.674736 27.634366       0.8345       0.5488\u001b[0m\n",
      "\u001b[31m###score: train_loss### 96.67473595961928\u001b[0m\n",
      "\u001b[31m###score: val_loss### 27.63436570763588\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.8345238095238094\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.5487804878048781\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2019-10-27 08:08:45,413 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:08:45,420 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_a18d1f30-a943-457b-a030-f48859335e40_20191027_080845.csv: \u001b[0m\n",
      "\u001b[31m[[4276   63]\n",
      " [ 192  719]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:08:45,427 - algorithms.BertTrain - INFO - Train set result details: 0.8493797991730655\u001b[0m\n",
      "\u001b[31m2019-10-27 08:08:45,427 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:08:52,198 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_47ebaaa9-9af2-4230-b81e-5960c6cdbafd_20191027_080852.csv: \u001b[0m\n",
      "\u001b[31m[[463  32]\n",
      " [ 45  44]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:08:52,200 - algorithms.BertTrain - INFO - Validation set result details: 0.5333333333333333 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:08:52,200 - algorithms.BertTrain - INFO - Run   4769    17     11826     3/657         0% 84.740633 26.632005       0.8494       0.5333\u001b[0m\n",
      "\u001b[31m###score: train_loss### 84.74063269048929\u001b[0m\n",
      "\u001b[31m###score: val_loss### 26.63200479745865\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.8493797991730655\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.5333333333333333\u001b[0m\n",
      "\u001b[31m2019-10-27 08:13:10,301 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:13:10,309 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_789dda81-5e43-4287-8507-222a33f7481e_20191027_081310.csv: \u001b[0m\n",
      "\u001b[31m[[4297   42]\n",
      " [ 192  719]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:13:10,315 - algorithms.BertTrain - INFO - Train set result details: 0.8600478468899522\u001b[0m\n",
      "\u001b[31m2019-10-27 08:13:10,316 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:13:17,090 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_31c09118-d8dd-4606-b749-e59d0dae9d32_20191027_081317.csv: \u001b[0m\n",
      "\u001b[31m[[471  24]\n",
      " [ 47  42]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:13:17,092 - algorithms.BertTrain - INFO - Validation set result details: 0.5419354838709678 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:13:17,092 - algorithms.BertTrain - INFO - Run   5034    18     12483     3/657         0% 73.804333 28.055556       0.8600       0.5419\u001b[0m\n",
      "\u001b[31m###score: train_loss### 73.80433275923133\u001b[0m\n",
      "\u001b[31m###score: val_loss### 28.055555798113346\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.8600478468899522\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.5419354838709678\u001b[0m\n",
      "\u001b[31m2019-10-27 08:17:35,254 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:17:35,262 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_0b5af675-d167-4b61-adde-999376e76ef1_20191027_081735.csv: \u001b[0m\n",
      "\u001b[31m[[4283   56]\n",
      " [ 137  774]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:17:35,269 - algorithms.BertTrain - INFO - Train set result details: 0.8891441700172314\u001b[0m\n",
      "\u001b[31m2019-10-27 08:17:35,269 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:17:42,044 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_c2dfd670-462f-4905-b139-3065bb884058_20191027_081742.csv: \u001b[0m\n",
      "\u001b[31m[[466  29]\n",
      " [ 35  54]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:17:42,045 - algorithms.BertTrain - INFO - Validation set result details: 0.627906976744186 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:17:42,045 - algorithms.BertTrain - INFO - Snapshotting because the current score 0.627906976744186 is greater than 0.5512820512820513 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:17:42,045 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/model/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 08:17:42,564 - algorithms.BertTrain - INFO - Run   5299    19     13140     3/657         0% 63.695180 23.620352       0.8891       0.6279\u001b[0m\n",
      "\u001b[31m###score: train_loss### 63.695179637521505\u001b[0m\n",
      "\u001b[31m###score: val_loss### 23.62035208567977\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.8891441700172314\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.627906976744186\u001b[0m\n",
      "\u001b[31m2019-10-27 08:22:00,766 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:22:00,774 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_6a77d553-d76b-4abb-b06f-2845eb6b467e_20191027_082200.csv: \u001b[0m\n",
      "\u001b[31m[[4271   68]\n",
      " [  85  826]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:22:00,781 - algorithms.BertTrain - INFO - Train set result details: 0.9152354570637119\u001b[0m\n",
      "\u001b[31m2019-10-27 08:22:00,781 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:22:07,559 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_ab2e7d92-ebd7-42df-8a29-f422d92808bf_20191027_082207.csv: \u001b[0m\n",
      "\u001b[31m[[457  38]\n",
      " [ 37  52]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:22:07,561 - algorithms.BertTrain - INFO - Validation set result details: 0.5810055865921788 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:22:07,561 - algorithms.BertTrain - INFO - Run   5564    20     13797     3/657         0% 53.408359 29.065730       0.9152       0.5810\u001b[0m\n",
      "\u001b[31m###score: train_loss### 53.408358573913574\u001b[0m\n",
      "\u001b[31m###score: val_loss### 29.065729893743992\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.9152354570637119\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.5810055865921788\u001b[0m\n",
      "\u001b[31m2019-10-27 08:26:25,395 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:26:25,403 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_38ea3af0-f652-45c3-9c67-185ff43b8a6f_20191027_082625.csv: \u001b[0m\n",
      "\u001b[31m[[4306   33]\n",
      " [ 165  746]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:26:25,409 - algorithms.BertTrain - INFO - Train set result details: 0.8828402366863904\u001b[0m\n",
      "\u001b[31m2019-10-27 08:26:25,410 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:26:32,187 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_4f801bed-0270-4ca4-8a27-857a2f4cbd5c_20191027_082632.csv: \u001b[0m\n",
      "\u001b[31m[[472  23]\n",
      " [ 43  46]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:26:32,189 - algorithms.BertTrain - INFO - Validation set result details: 0.5822784810126582 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:26:32,189 - algorithms.BertTrain - INFO - Run   5829    21     14454     3/657         0% 60.689600 28.589668       0.8828       0.5823\u001b[0m\n",
      "\u001b[31m###score: train_loss### 60.68959990143776\u001b[0m\n",
      "\u001b[31m###score: val_loss### 28.589667946100235\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.8828402366863904\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.5822784810126582\u001b[0m\n",
      "\u001b[31m2019-10-27 08:30:50,103 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:30:50,111 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_719437cc-ddae-47ce-b23f-74ab43e8fa29_20191027_083050.csv: \u001b[0m\n",
      "\u001b[31m[[4258   81]\n",
      " [  41  870]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:30:50,118 - algorithms.BertTrain - INFO - Train set result details: 0.9344790547798068\u001b[0m\n",
      "\u001b[31m2019-10-27 08:30:50,118 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:30:56,897 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_31508ec9-57cd-42c0-81d1-26247ab9130c_20191027_083056.csv: \u001b[0m\n",
      "\u001b[31m[[451  44]\n",
      " [ 30  59]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:30:56,899 - algorithms.BertTrain - INFO - Validation set result details: 0.6145833333333334 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:30:56,899 - algorithms.BertTrain - INFO - Run   6094    22     15111     3/657         0% 40.048966 32.412144       0.9345       0.6146\u001b[0m\n",
      "\u001b[31m###score: train_loss### 40.048966251313686\u001b[0m\n",
      "\u001b[31m###score: val_loss### 32.41214370727539\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.9344790547798068\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.6145833333333334\u001b[0m\n",
      "\u001b[31m2019-10-27 08:35:14,740 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:35:14,748 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_3f5adc5e-675d-411c-9a0c-b83f4ed0b601_20191027_083514.csv: \u001b[0m\n",
      "\u001b[31m[[4281   58]\n",
      " [  45  866]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:35:14,755 - algorithms.BertTrain - INFO - Train set result details: 0.9438692098092643\u001b[0m\n",
      "\u001b[31m2019-10-27 08:35:14,755 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:35:21,534 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_60f02c6b-225b-48cf-a03b-5e5587d232dd_20191027_083521.csv: \u001b[0m\n",
      "\u001b[31m[[453  42]\n",
      " [ 31  58]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:35:21,535 - algorithms.BertTrain - INFO - Validation set result details: 0.6137566137566138 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:35:21,536 - algorithms.BertTrain - INFO - Run   6358    23     15768     3/657         0% 39.105022 31.990637       0.9439       0.6138\u001b[0m\n",
      "\u001b[31m###score: train_loss### 39.105022478848696\u001b[0m\n",
      "\u001b[31m###score: val_loss### 31.990636587142944\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.9438692098092643\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.6137566137566138\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2019-10-27 08:39:39,276 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:39:39,284 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_a3e28936-63f4-43ff-bc84-998ad94a3ee5_20191027_083939.csv: \u001b[0m\n",
      "\u001b[31m[[4313   26]\n",
      " [  55  856]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:39:39,291 - algorithms.BertTrain - INFO - Train set result details: 0.9548243167875069\u001b[0m\n",
      "\u001b[31m2019-10-27 08:39:39,291 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:39:46,069 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_7c2e6594-97e7-4d59-9594-06c93e09942d_20191027_083946.csv: \u001b[0m\n",
      "\u001b[31m[[463  32]\n",
      " [ 33  56]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:39:46,071 - algorithms.BertTrain - INFO - Validation set result details: 0.6327683615819208 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:39:46,071 - algorithms.BertTrain - INFO - Snapshotting because the current score 0.6327683615819208 is greater than 0.627906976744186 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:39:46,071 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/model/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 08:39:46,645 - algorithms.BertTrain - INFO - Run   6624    24     16425     3/657         0% 31.879266 30.869727       0.9548       0.6328\u001b[0m\n",
      "\u001b[31m###score: train_loss### 31.879265643656254\u001b[0m\n",
      "\u001b[31m###score: val_loss### 30.86972700804472\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.9548243167875069\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.6327683615819208\u001b[0m\n",
      "\u001b[31m2019-10-27 08:44:04,416 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:44:04,424 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_7a30d64c-29c9-47de-b041-465ac5599b0f_20191027_084404.csv: \u001b[0m\n",
      "\u001b[31m[[4298   41]\n",
      " [  34  877]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:44:04,431 - algorithms.BertTrain - INFO - Train set result details: 0.9589939857845818\u001b[0m\n",
      "\u001b[31m2019-10-27 08:44:04,431 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:44:11,205 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_7f1d96e0-1493-4ed9-aaa2-2359e3eb18e9_20191027_084411.csv: \u001b[0m\n",
      "\u001b[31m[[454  41]\n",
      " [ 27  62]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:44:11,206 - algorithms.BertTrain - INFO - Validation set result details: 0.6458333333333333 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:44:11,207 - algorithms.BertTrain - INFO - Snapshotting because the current score 0.6458333333333333 is greater than 0.6327683615819208 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:44:11,207 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/model/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 08:44:11,735 - algorithms.BertTrain - INFO - Run   6889    25     17082     3/657         0% 28.559410 32.706815       0.9590       0.6458\u001b[0m\n",
      "\u001b[31m###score: train_loss### 28.559410352259874\u001b[0m\n",
      "\u001b[31m###score: val_loss### 32.70681484043598\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.9589939857845818\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.6458333333333333\u001b[0m\n",
      "\u001b[31m2019-10-27 08:48:29,421 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:48:29,429 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_ed091ad5-f938-4a15-981f-c4295fe2f680_20191027_084829.csv: \u001b[0m\n",
      "\u001b[31m[[4294   45]\n",
      " [  35  876]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:48:29,436 - algorithms.BertTrain - INFO - Train set result details: 0.9563318777292577\u001b[0m\n",
      "\u001b[31m2019-10-27 08:48:29,436 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:48:36,210 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_f4fb069c-f683-466e-995d-af4c4a0ad1a1_20191027_084836.csv: \u001b[0m\n",
      "\u001b[31m[[455  40]\n",
      " [ 27  62]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:48:36,211 - algorithms.BertTrain - INFO - Validation set result details: 0.6492146596858639 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:48:36,211 - algorithms.BertTrain - INFO - Snapshotting because the current score 0.6492146596858639 is greater than 0.6458333333333333 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:48:36,211 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/model/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 08:48:36,736 - algorithms.BertTrain - INFO - Run   7154    26     17739     3/657         0% 27.331326 32.548459       0.9563       0.6492\u001b[0m\n",
      "\u001b[31m###score: train_loss### 27.331326477229595\u001b[0m\n",
      "\u001b[31m###score: val_loss### 32.54845937713981\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.9563318777292577\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.6492146596858639\u001b[0m\n",
      "\u001b[31m2019-10-27 08:52:54,349 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:52:54,357 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_55da9200-d298-4ada-8ff8-0d8c9b987b13_20191027_085254.csv: \u001b[0m\n",
      "\u001b[31m[[4294   45]\n",
      " [  29  882]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:52:54,364 - algorithms.BertTrain - INFO - Train set result details: 0.9597388465723613\u001b[0m\n",
      "\u001b[31m2019-10-27 08:52:54,364 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:53:01,141 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_90fbc2c1-e206-4a22-90c1-59cafb271d9f_20191027_085301.csv: \u001b[0m\n",
      "\u001b[31m[[454  41]\n",
      " [ 24  65]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:53:01,142 - algorithms.BertTrain - INFO - Validation set result details: 0.6666666666666666 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:53:01,142 - algorithms.BertTrain - INFO - Snapshotting because the current score 0.6666666666666666 is greater than 0.6492146596858639 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:53:01,142 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/model/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 08:53:01,675 - algorithms.BertTrain - INFO - Run   7419    27     18396     3/657         0% 25.878721 31.964091       0.9597       0.6667\u001b[0m\n",
      "\u001b[31m###score: train_loss### 25.878721483051777\u001b[0m\n",
      "\u001b[31m###score: val_loss### 31.964090831577778\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.9597388465723613\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.6666666666666666\u001b[0m\n",
      "\u001b[31m2019-10-27 08:57:19,303 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:57:19,310 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_003d522e-e866-4abf-b673-a9836305f810_20191027_085719.csv: \u001b[0m\n",
      "\u001b[31m[[4303   36]\n",
      " [  22  889]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:57:19,317 - algorithms.BertTrain - INFO - Train set result details: 0.9684095860566448\u001b[0m\n",
      "\u001b[31m2019-10-27 08:57:19,317 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-27 08:57:26,090 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_0bd323d2-a99b-4622-b279-d10b88d9272d_20191027_085726.csv: \u001b[0m\n",
      "\u001b[31m[[456  39]\n",
      " [ 25  64]]\u001b[0m\n",
      "\u001b[31m2019-10-27 08:57:26,091 - algorithms.BertTrain - INFO - Validation set result details: 0.6666666666666666 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:57:26,091 - algorithms.BertTrain - INFO - Snapshotting because the current loss 31.468735102564096 is lower than 31.964090831577778 \u001b[0m\n",
      "\u001b[31m2019-10-27 08:57:26,091 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/output/data/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-27 08:57:26,616 - algorithms.BertTrain - INFO - Run   7684    28     19053     3/657         0% 23.436782 31.468735       0.9684       0.6667\u001b[0m\n",
      "\u001b[31m###score: train_loss### 23.4367818236351\u001b[0m\n",
      "\u001b[31m###score: val_loss### 31.468735102564096\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.9684095860566448\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.6666666666666666\u001b[0m\n"
     ]
    },
    {
     "ename": "EndpointConnectionError",
     "evalue": "Could not connect to the endpoint URL: \"https://api.sagemaker.us-east-2.amazonaws.com/\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 141\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/httpsession.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    638\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 639\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    640\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Disabled, indicate to re-raise the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 150\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <botocore.awsrequest.AWSHTTPSConnection object at 0x10c1a1fd0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEndpointConnectionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0731e612c7b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \"\"\"\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   1477\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_describe_job_call\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m                 \u001b[0mlast_describe_job_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             http, parsed_response = self._make_request(\n\u001b[0;32m--> 648\u001b[0;31m                 operation_model, request_dict, request_context)\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         self.meta.events.emit(\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, operation_model, request_dict, request_context)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             self.meta.events.emit(\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36mmake_request\u001b[0;34m(self, operation_model, request_dict)\u001b[0m\n\u001b[1;32m    100\u001b[0m         logger.debug(\"Making request for %s with params: %s\",\n\u001b[1;32m    101\u001b[0m                      operation_model, request_dict)\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, request_dict, operation_model)\u001b[0m\n\u001b[1;32m    135\u001b[0m             request, operation_model, context)\n\u001b[1;32m    136\u001b[0m         while self._needs_retry(attempts, operation_model, request_dict,\n\u001b[0;32m--> 137\u001b[0;31m                                 success_response, exception):\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mattempts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# If there is a stream associated with the request, we need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_needs_retry\u001b[0;34m(self, attempts, operation_model, request_dict, response, caught_exception)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0moperation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattempts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             caught_exception=caught_exception, request_dict=request_dict)\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mhandler_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_non_none_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandler_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/hooks.py\u001b[0m in \u001b[0;36memit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0maliased_event_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_event_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_emitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maliased_event_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit_until_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/hooks.py\u001b[0m in \u001b[0;36memit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m                  \u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_emit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit_until_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/hooks.py\u001b[0m in \u001b[0;36m_emit\u001b[0;34m(self, event_name, kwargs, stop_on_response)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers_to_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Event %s: calling handler %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0mresponses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_on_response\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, attempts, response, caught_exception, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \"\"\"\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaught_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattempts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retry needed, action of: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempt_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaught_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         should_retry = self._should_retry(attempt_number, response,\n\u001b[0;32m--> 251\u001b[0;31m                                           caught_exception)\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshould_retry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattempt_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_attempts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m_should_retry\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# If we've exceeded the max attempts we just let the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;31m# propogate if one has occurred.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattempt_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaught_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchecker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             checker_response = checker(attempt_number, response,\n\u001b[0;32m--> 317\u001b[0;31m                                        caught_exception)\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchecker_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mchecker_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcaught_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             return self._check_caught_exception(\n\u001b[0;32m--> 223\u001b[0;31m                 attempt_number, caught_exception)\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Both response and caught_exception are None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m_check_caught_exception\u001b[0;34m(self, attempt_number, caught_exception)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the MaxAttemptsDecorator is not interested in retrying the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# then this exception just propogates out past the retry code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mcaught_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_do_get_response\u001b[0;34m(self, request, operation_model)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mhttp_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_non_none_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhttp_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0mhttp_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPClientError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/httpsession.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNewConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaierror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEndpointConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mProxyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mProxyConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxy_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEndpointConnectionError\u001b[0m: Could not connect to the endpoint URL: \"https://api.sagemaker.us-east-2.amazonaws.com/\""
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
