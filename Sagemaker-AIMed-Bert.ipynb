{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Set  up  accounts and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sagemaker==1.39.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "account_id =  boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "\n",
    "#role = sagemaker.get_execution_role()\n",
    "role=\"arn:aws:iam::{}:role/service-role/AmazonSageMaker-ExecutionRole-20190118T115449\".format(account_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Setup image and instance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_custom_image_name=\"ppi-extractor:gpu-1.0.0-201910130520\"\n",
    "instance_type = \"ml.p3.8xlarge\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_repo = \"{}.dkr.ecr.{}.amazonaws.com/{}\".format(account_id, region, pytorch_custom_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Configure train/ test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"aegovan-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainfile = \"s3://{}/aimed/AIMedtrain.json\".format(bucket)\n",
    "#trainfile = \"s3://{}/aimed/AIMedFull.json\".format(bucket)\n",
    "trainfile=\"s3://{}/aimed/AIMedtrain_preprocessed.json\".format(bucket)\n",
    "\n",
    "valfile=\"s3://{}/aimed/AIMedval_preprocessed.json\".format(bucket)\n",
    "# trainfile = \"s3://{}/aimed/AIMedtrain_pubmedoverlap.json\".format(bucket)\n",
    "# valfile=\"s3://{}/aimed/AIMedval_pubmedoverlap.json\".format(bucket)\n",
    "#embeddingfile=\"s3://{}/embeddings/PubMed-and-PMC-w2v.bin.txt\".format(bucket)\n",
    "#embeddingfile=\"s3://{}/embeddings/bio_nlp_vec/PubMed-shuffle-win-30.bin.txt\".format(bucket)\n",
    "pretrained_bert=\"s3://{}/embeddings/bert/\".format(bucket)\n",
    "\n",
    "\n",
    "s3_output_path= \"s3://{}/results/\".format(bucket)\n",
    "s3_code_path= \"s3://{}/aimed_bert_code\".format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_inputs = {\n",
    "    \"train\" : trainfile,\n",
    "    \"val\" :valfile,\n",
    "    \"PRETRAINED_BIOBERT\" : pretrained_bert\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertNetworkFactoryhyperparameters = {\n",
    "  #  \"dataset\":\"PpiAimedDatasetFactory\",\n",
    "    \"dataset\":\"PpiAimedDatasetPreprocessedFactory\",\n",
    "    \"network\" :\"RelationExtractorBioBertFactory\",\n",
    "    \"trainfile\":trainfile.split(\"/\")[-1],\n",
    "    \"valfile\":valfile.split(\"/\")[-1],\n",
    "    \"batchsize\": \"8\",\n",
    "    \"accumulation_steps\" : \"4\",\n",
    "    \"epochs\" : \"1000\",   \n",
    "    \"log-level\" : \"INFO\",\n",
    "    \"learningrate\":.001,\n",
    "    \"earlystoppingpatience\":20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [{\"Name\": \"TrainLoss\",\n",
    "                     \"Regex\": \"###score: train_loss### (\\d*[.]?\\d*)\"}\n",
    "                    ,{\"Name\": \"ValidationLoss\",\n",
    "                     \"Regex\": \"###score: val_loss### (\\d*[.]?\\d*)\"}\n",
    "                    ,{\"Name\": \"TrainFScore\",\n",
    "                     \"Regex\": \"###score: train_fscore### (\\d*[.]?\\d*)\"}\n",
    "                   ,{\"Name\": \"ValidationFScore\",\n",
    "                     \"Regex\": \"###score: val_fscore### (\\d*[.]?\\d*)\"}\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commit 43023662c11e1d76bddb3fc70c79dfc85bdc9ab5\n",
      "    Add gradient accumulation\n"
     ]
    }
   ],
   "source": [
    "!git log -1 | head -1\n",
    "!git log -1 | head -5 | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_config = {'repo': 'https://github.com/elangovana/PPI-typed-relation-extractor.git',\n",
    "              'branch': 'master',\n",
    "            #  'commit': '58a09e154935248667062a36fdae7d86b86b477c'\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = BertNetworkFactoryhyperparameters\n",
    "inputs = pub_inputs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accumulation_steps': '4',\n",
       " 'batchsize': '8',\n",
       " 'dataset': 'PpiAimedDatasetPreprocessedFactory',\n",
       " 'earlystoppingpatience': 20,\n",
       " 'epochs': '1000',\n",
       " 'learningrate': 0.001,\n",
       " 'log-level': 'INFO',\n",
       " 'network': 'RelationExtractorBioBertFactory',\n",
       " 'trainfile': 'AIMedtrain_preprocessed.json',\n",
       " 'valfile': 'AIMedval_preprocessed.json'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PRETRAINED_BIOBERT': 's3://aegovan-data/embeddings/bert/',\n",
       " 'train': 's3://aegovan-data/aimed/AIMedtrain_preprocessed.json',\n",
       " 'val': 's3://aegovan-data/aimed/AIMedval_preprocessed.json'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "     #entry_point='main_train_k_fold.py',\n",
    "    entry_point='main_train_bert.py',\n",
    "                    source_dir = 'source/algorithms',\n",
    "                    dependencies =['source/algorithms', 'source/datasets', 'source/preprocessor', 'source/modelnetworks','source/trainpipelinesbuilders'],\n",
    "                    role=role,\n",
    "                    framework_version =\"1.0.0\",\n",
    "                    py_version='py3',\n",
    "                    git_config= git_config,\n",
    "                    image_name= docker_repo,\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type=instance_type,\n",
    "                    hyperparameters =hyperparameters,\n",
    "                    output_path=s3_output_path,\n",
    "                    metric_definitions=metric_definitions,\n",
    "                    #train_use_spot_instances = True\n",
    "                    train_volume_size=30,\n",
    "                    code_location=s3_code_path,\n",
    "                    base_job_name =\"aimed-ppi-bert-acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-21 10:45:26 Starting - Starting the training job...\n",
      "2019-10-21 10:45:28 Starting - Launching requested ML instances...\n",
      "2019-10-21 10:46:26 Starting - Preparing the instances for training......\n",
      "2019-10-21 10:47:47 Downloading - Downloading input data\n",
      "2019-10-21 10:47:47 Training - Downloading the training image..........\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:47,834 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:47,879 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:47,879 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:48,208 sagemaker-containers INFO     Module main_train_bert does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:48,208 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:48,209 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:48,209 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: main-train-bert\n",
      "  Running setup.py bdist_wheel for main-train-bert: started\n",
      "  Running setup.py bdist_wheel for main-train-bert: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9uabf69f/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built main-train-bert\u001b[0m\n",
      "\u001b[31mInstalling collected packages: main-train-bert\u001b[0m\n",
      "\u001b[31mSuccessfully installed main-train-bert-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.3.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:50,563 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"val\": \"/opt/ml/input/data/val\",\n",
      "        \"PRETRAINED_BIOBERT\": \"/opt/ml/input/data/PRETRAINED_BIOBERT\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"learningrate\": 0.001,\n",
      "        \"trainfile\": \"AIMedtrain_preprocessed.json\",\n",
      "        \"batchsize\": \"8\",\n",
      "        \"accumulation_steps\": \"4\",\n",
      "        \"network\": \"RelationExtractorBioBertFactory\",\n",
      "        \"log-level\": \"INFO\",\n",
      "        \"valfile\": \"AIMedval_preprocessed.json\",\n",
      "        \"dataset\": \"PpiAimedDatasetPreprocessedFactory\",\n",
      "        \"epochs\": \"1000\",\n",
      "        \"earlystoppingpatience\": 20\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"PRETRAINED_BIOBERT\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"aimed-ppi-bert-acc-2019-10-21-10-45-13-031\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://aegovan-data/aimed_bert_code/aimed-ppi-bert-acc-2019-10-21-10-45-13-031/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"main_train_bert\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"main_train_bert.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"accumulation_steps\":\"4\",\"batchsize\":\"8\",\"dataset\":\"PpiAimedDatasetPreprocessedFactory\",\"earlystoppingpatience\":20,\"epochs\":\"1000\",\"learningrate\":0.001,\"log-level\":\"INFO\",\"network\":\"RelationExtractorBioBertFactory\",\"trainfile\":\"AIMedtrain_preprocessed.json\",\"valfile\":\"AIMedval_preprocessed.json\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=main_train_bert.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"PRETRAINED_BIOBERT\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"PRETRAINED_BIOBERT\",\"train\",\"val\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=main_train_bert\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://aegovan-data/aimed_bert_code/aimed-ppi-bert-acc-2019-10-21-10-45-13-031/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"PRETRAINED_BIOBERT\":\"/opt/ml/input/data/PRETRAINED_BIOBERT\",\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"accumulation_steps\":\"4\",\"batchsize\":\"8\",\"dataset\":\"PpiAimedDatasetPreprocessedFactory\",\"earlystoppingpatience\":20,\"epochs\":\"1000\",\"learningrate\":0.001,\"log-level\":\"INFO\",\"network\":\"RelationExtractorBioBertFactory\",\"trainfile\":\"AIMedtrain_preprocessed.json\",\"valfile\":\"AIMedval_preprocessed.json\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"PRETRAINED_BIOBERT\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"aimed-ppi-bert-acc-2019-10-21-10-45-13-031\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://aegovan-data/aimed_bert_code/aimed-ppi-bert-acc-2019-10-21-10-45-13-031/source/sourcedir.tar.gz\",\"module_name\":\"main_train_bert\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"main_train_bert.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--accumulation_steps\",\"4\",\"--batchsize\",\"8\",\"--dataset\",\"PpiAimedDatasetPreprocessedFactory\",\"--earlystoppingpatience\",\"20\",\"--epochs\",\"1000\",\"--learningrate\",\"0.001\",\"--log-level\",\"INFO\",\"--network\",\"RelationExtractorBioBertFactory\",\"--trainfile\",\"AIMedtrain_preprocessed.json\",\"--valfile\",\"AIMedval_preprocessed.json\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_PRETRAINED_BIOBERT=/opt/ml/input/data/PRETRAINED_BIOBERT\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_HP_LEARNINGRATE=0.001\u001b[0m\n",
      "\u001b[31mSM_HP_TRAINFILE=AIMedtrain_preprocessed.json\u001b[0m\n",
      "\u001b[31mSM_HP_BATCHSIZE=8\u001b[0m\n",
      "\u001b[31mSM_HP_ACCUMULATION_STEPS=4\u001b[0m\n",
      "\u001b[31mSM_HP_NETWORK=RelationExtractorBioBertFactory\u001b[0m\n",
      "\u001b[31mSM_HP_LOG-LEVEL=INFO\u001b[0m\n",
      "\u001b[31mSM_HP_VALFILE=AIMedval_preprocessed.json\u001b[0m\n",
      "\u001b[31mSM_HP_DATASET=PpiAimedDatasetPreprocessedFactory\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=1000\u001b[0m\n",
      "\u001b[31mSM_HP_EARLYSTOPPINGPATIENCE=20\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m main_train_bert --accumulation_steps 4 --batchsize 8 --dataset PpiAimedDatasetPreprocessedFactory --earlystoppingpatience 20 --epochs 1000 --learningrate 0.001 --log-level INFO --network RelationExtractorBioBertFactory --trainfile AIMedtrain_preprocessed.json --valfile AIMedval_preprocessed.json\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31m['--accumulation_steps', '4', '--batchsize', '8', '--learningrate', '0.001']\u001b[0m\n",
      "\u001b[31m{'dataset': 'PpiAimedDatasetPreprocessedFactory', 'network': 'RelationExtractorBioBertFactory', 'trainfile': 'AIMedtrain_preprocessed.json', 'traindir': '/opt/ml/input/data/train', 'valfile': 'AIMedval_preprocessed.json', 'valdir': '/opt/ml/input/data/val', 'pretrained_biobert_dir': '/opt/ml/input/data/PRETRAINED_BIOBERT', 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'epochs': 1000, 'earlystoppingpatience': 20, 'interaction_type': None, 'log_level': 'INFO'}\u001b[0m\n",
      "\u001b[31m{'accumulation_steps': '4', 'batchsize': '8', 'learningrate': '0.001'}\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:52,943 - trainpipelinesbuilders.BertTrainInferenceBuilder - INFO - Retrieving key batchsize with default 32, found 8\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:52,943 - trainpipelinesbuilders.BertTrainInferenceBuilder - INFO - Retrieving key pretrained_biobert_dir with default None, found /opt/ml/input/data/PRETRAINED_BIOBERT\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:52,944 - pytorch_pretrained_bert.tokenization - INFO - loading vocabulary file /opt/ml/input/data/PRETRAINED_BIOBERT/vocab.txt\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:52,999 - pytorch_pretrained_bert.tokenization - INFO - loading vocabulary file /opt/ml/input/data/PRETRAINED_BIOBERT/vocab.txt\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:53,042 - modelnetworks.RelationExtractorBioBertFactory - INFO - Retrieving key pretrained_biobert_dir with default None, found /opt/ml/input/data/PRETRAINED_BIOBERT\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:53,043 - pytorch_pretrained_bert.modeling - INFO - loading archive file /opt/ml/input/data/PRETRAINED_BIOBERT\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:53,044 - pytorch_pretrained_bert.modeling - INFO - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2019-10-21 10:49:57,746 - pytorch_pretrained_bert.modeling - INFO - Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:57,746 - pytorch_pretrained_bert.modeling - INFO - Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\u001b[0m\n",
      "\u001b[31mBertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): BertLayerNorm()\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): BertLayerNorm()\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\u001b[0m\n",
      "\u001b[31m)\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:57,748 - trainpipelinesbuilders.BertTrainInferenceBuilder - INFO - Using model <class 'modelnetworks.RelationExtractorBioBert.RelationExtractorBioBert'>\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:57,749 - trainpipelinesbuilders.BertTrainInferenceBuilder - INFO - \u001b[0m\n",
      "\u001b[31mRelationExtractorBioBert(\n",
      "  (model): BertForSequenceClassification(\n",
      "    (bert): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): BertLayerNorm()\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): BertLayerNorm()\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): BertLayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1)\n",
      "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  )\u001b[0m\n",
      "\u001b[31m)\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:57,750 - trainpipelinesbuilders.BertTrainInferenceBuilder - INFO - Using loss function <class 'torch.nn.modules.loss.CrossEntropyLoss'>\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:57,750 - trainpipelinesbuilders.BertTrainInferenceBuilder - INFO - Retrieving key accumulation_steps with default 1, found 4\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:57,924 - algorithms.BertTrainInferencePipeline - INFO - Train set has 5142 records, val has 692\u001b[0m\n",
      "\u001b[31m2019-10-21 10:49:57,924 - algorithms.transform_berttext_tokenise - INFO - Transforming TransformBertTextTokenise\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:01,930 - algorithms.transform_berttext_tokenise - INFO - Completed TransformBertTextTokenise\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:01,930 - algorithms.transform_berttext_token_to_index - INFO - Transforming TransformBertTextTokenToIndex\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:02,407 - algorithms.transform_berttext_token_to_index - INFO - Completed TransformBertTextTokenToIndex\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:02,418 - algorithms.transform_berttext_tokenise - INFO - Transforming TransformBertTextTokenise\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:02,936 - algorithms.transform_berttext_tokenise - INFO - Completed TransformBertTextTokenise\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:02,936 - algorithms.transform_berttext_token_to_index - INFO - Transforming TransformBertTextTokenToIndex\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:02,998 - algorithms.transform_berttext_token_to_index - INFO - Completed TransformBertTextTokenToIndex\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:03,000 - algorithms.transform_label_encoder - INFO - Running TransformLabelEncoder\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:03,001 - algorithms.transform_label_encoder - INFO - Complete TransformLabelEncoder\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:03,049 - algorithms.BertTrainInferencePipeline - INFO - Retrieving key learningrate with default .01, found 0.001\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:03,049 - algorithms.BertTrainInferencePipeline - INFO - Retrieving key weight_decay with default .0001, found .0001\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:03,049 - pytorch_pretrained_bert.optimization - WARNING - t_total value of -1 results in schedule not being applied\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:03,050 - algorithms.BertTrainInferencePipeline - INFO - Using optimiser <class 'pytorch_pretrained_bert.optimization.BertAdam'>\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:03,051 - algorithms.transform_label_rehaper - INFO - Loading int 1 to tensor 1\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:03,051 - algorithms.BertTrainInferencePipeline - INFO - Positive label True is 1\u001b[0m\n",
      "\u001b[31m2019-10-21 10:50:03,078 - algorithms.BertTrain - INFO - using score : <class 'algorithms.result_scorer_f1.ResultScorerF1'>\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-10-21 10:49:46 Training - Training image download completed. Training in progress.\u001b[31m2019-10-21 10:54:18,305 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 10:54:18,345 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_18044182-b24f-435a-8e25-36fa7212e37c_20191021_105418.csv: \u001b[0m\n",
      "\u001b[31m[[4258    0]\n",
      " [ 884    0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 10:54:18,353 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 10:54:18,353 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 10:54:26,199 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_03d5c9cf-f712-4a9a-9406-7577b9e473c4_20191021_105426.csv: \u001b[0m\n",
      "\u001b[31m[[576   0]\n",
      " [116   0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 10:54:26,201 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-21 10:54:26,201 - algorithms.BertTrain - INFO - Snapshotting because the current score 0.0 is greater than None \u001b[0m\n",
      "\u001b[31m2019-10-21 10:54:26,201 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/model/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-21 10:54:26,656 - algorithms.BertTrain - INFO - Run    263     0       643     7/643         1% 334.148409 45.065794       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 334.14840909838676\u001b[0m\n",
      "\u001b[31m###score: val_loss### 45.065793603658676\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 10:58:37,796 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 10:58:37,804 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_40309976-8668-48c7-9cef-9efd11776a3a_20191021_105837.csv: \u001b[0m\n",
      "\u001b[31m[[4258    0]\n",
      " [ 884    0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 10:58:37,811 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 10:58:37,811 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 10:58:45,717 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_6b57bc8a-4a1f-4813-9a53-64101fad7533_20191021_105845.csv: \u001b[0m\n",
      "\u001b[31m[[576   0]\n",
      " [116   0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 10:58:45,719 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-21 10:58:45,719 - algorithms.BertTrain - INFO - Snapshotting because the current loss 42.95590764284134 is lower than 45.065793603658676 \u001b[0m\n",
      "\u001b[31m2019-10-21 10:58:45,719 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/output/data/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-21 10:58:46,150 - algorithms.BertTrain - INFO - Run    523     1      1286     7/643         1% 318.815711 42.955908       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 318.8157112002373\u001b[0m\n",
      "\u001b[31m###score: val_loss### 42.95590764284134\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:02:57,619 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:02:57,626 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_eda197b2-d8b0-40ac-b2bb-aeba6a5803a8_20191021_110257.csv: \u001b[0m\n",
      "\u001b[31m[[4258    0]\n",
      " [ 884    0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:02:57,633 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:02:57,633 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:03:05,531 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_532e38c3-9cf8-40a9-9d74-edb325746561_20191021_110305.csv: \u001b[0m\n",
      "\u001b[31m[[576   0]\n",
      " [116   0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:03:05,533 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-21 11:03:05,533 - algorithms.BertTrain - INFO - Snapshotting because the current loss 39.629714757204056 is lower than 42.95590764284134 \u001b[0m\n",
      "\u001b[31m2019-10-21 11:03:05,533 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/output/data/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-21 11:03:06,060 - algorithms.BertTrain - INFO - Run    782     2      1929     7/643         1% 295.150924 39.629715       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 295.15092438459396\u001b[0m\n",
      "\u001b[31m###score: val_loss### 39.629714757204056\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:07:17,356 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:07:17,363 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_4601df02-36cc-4138-b70c-70181580fe17_20191021_110717.csv: \u001b[0m\n",
      "\u001b[31m[[4258    0]\n",
      " [ 884    0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:07:17,370 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:07:17,370 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:07:25,263 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_9c7952d4-681d-4523-b5b1-18d1ac20fc5f_20191021_110725.csv: \u001b[0m\n",
      "\u001b[31m[[576   0]\n",
      " [116   0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:07:25,265 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-21 11:07:25,265 - algorithms.BertTrain - INFO - Run   1042     3      2572     7/643         1% 295.774040 39.728642       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 295.77404026687145\u001b[0m\n",
      "\u001b[31m###score: val_loss### 39.7286422252655\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:11:36,540 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:11:36,547 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_07831fd2-ec38-42a9-999f-81ae9f641ea3_20191021_111136.csv: \u001b[0m\n",
      "\u001b[31m[[4258    0]\n",
      " [ 884    0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:11:36,554 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:11:36,554 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:11:44,458 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_ffce58b2-dcb2-46e7-a6a6-30982bf6484a_20191021_111144.csv: \u001b[0m\n",
      "\u001b[31m[[576   0]\n",
      " [116   0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:11:44,459 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-21 11:11:44,460 - algorithms.BertTrain - INFO - Run   1301     4      3215     7/643         1% 297.151771 39.844976       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 297.1517709493637\u001b[0m\n",
      "\u001b[31m###score: val_loss### 39.8449764251709\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:15:55,854 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:15:55,861 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_193cc08f-dada-4ed8-b107-25edfa3a1d66_20191021_111555.csv: \u001b[0m\n",
      "\u001b[31m[[4258    0]\n",
      " [ 884    0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:15:55,868 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:15:55,868 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:16:03,771 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_4c994c19-3698-41fe-9524-01075932c0f2_20191021_111603.csv: \u001b[0m\n",
      "\u001b[31m[[576   0]\n",
      " [116   0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:16:03,772 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-21 11:16:03,773 - algorithms.BertTrain - INFO - Run   1560     5      3858     7/643         1% 316.594769 42.370112       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 316.5947687625885\u001b[0m\n",
      "\u001b[31m###score: val_loss### 42.37011194229126\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:20:15,152 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:20:15,160 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_9d750959-1db2-4222-8d23-0634dfba7296_20191021_112015.csv: \u001b[0m\n",
      "\u001b[31m[[4258    0]\n",
      " [ 884    0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:20:15,166 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:20:15,166 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:20:23,071 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_c61e57ed-af9e-45c3-8b34-74e275934c2b_20191021_112023.csv: \u001b[0m\n",
      "\u001b[31m[[576   0]\n",
      " [116   0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:20:23,073 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-21 11:20:23,073 - algorithms.BertTrain - INFO - Run   1819     6      4501     7/643         1% 297.426174 39.879255       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 297.4261736869812\u001b[0m\n",
      "\u001b[31m###score: val_loss### 39.87925511598587\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2019-10-21 11:24:34,444 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:24:34,452 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_2a730e76-e448-4085-b9d0-8edb1ecf3419_20191021_112434.csv: \u001b[0m\n",
      "\u001b[31m[[4258    0]\n",
      " [ 884    0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:24:34,458 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:24:34,458 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:24:42,361 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_2c7b7900-03a6-480c-9067-32155de74a0b_20191021_112442.csv: \u001b[0m\n",
      "\u001b[31m[[576   0]\n",
      " [116   0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:24:42,363 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-21 11:24:42,363 - algorithms.BertTrain - INFO - Snapshotting because the current loss 39.626810789108276 is lower than 39.629714757204056 \u001b[0m\n",
      "\u001b[31m2019-10-21 11:24:42,363 - algorithms.ModelSnapshotCallback - INFO - Snappshotting model to /opt/ml/output/data/best_snaphsotmodel.pt\u001b[0m\n",
      "\u001b[31m2019-10-21 11:24:42,908 - algorithms.BertTrain - INFO - Run   2079     7      5144     7/643         1% 295.336105 39.626811       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 295.33610516786575\u001b[0m\n",
      "\u001b[31m###score: val_loss### 39.626810789108276\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:28:54,632 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:28:54,639 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_99aa8b1b-f42f-4fa4-ad42-3b2b7ecc3e1e_20191021_112854.csv: \u001b[0m\n",
      "\u001b[31m[[4258    0]\n",
      " [ 884    0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:28:54,646 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:28:54,646 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:29:02,555 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_b9fbae8d-fd24-4fe7-8543-0b0c2983a6db_20191021_112902.csv: \u001b[0m\n",
      "\u001b[31m[[576   0]\n",
      " [116   0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:29:02,557 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-21 11:29:02,557 - algorithms.BertTrain - INFO - Run   2339     8      5787     7/643         1% 295.449430 39.639345       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 295.4494304060936\u001b[0m\n",
      "\u001b[31m###score: val_loss### 39.63934528827667\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:33:14,301 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:33:14,309 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_786e9aee-6148-403f-b7de-a1d4a3fb4e7a_20191021_113314.csv: \u001b[0m\n",
      "\u001b[31m[[4258    0]\n",
      " [ 884    0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:33:14,315 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:33:14,315 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:33:22,221 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_71f4d78a-33cd-4a37-adf8-f8e96973fc59_20191021_113322.csv: \u001b[0m\n",
      "\u001b[31m[[576   0]\n",
      " [116   0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:33:22,222 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-21 11:33:22,222 - algorithms.BertTrain - INFO - Run   2599     9      6430     7/643         1% 295.852673 39.686098       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 295.85267275571823\u001b[0m\n",
      "\u001b[31m###score: val_loss### 39.68609839677811\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:37:33,659 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:37:33,667 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_04b45f33-4a72-43b0-bd18-b198e12f6822_20191021_113733.csv: \u001b[0m\n",
      "\u001b[31m[[4258    0]\n",
      " [ 884    0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:37:33,675 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:37:33,675 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:37:41,579 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_5c700ae1-5e77-4954-9c7b-e5e57d1f0543_20191021_113741.csv: \u001b[0m\n",
      "\u001b[31m[[576   0]\n",
      " [116   0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:37:41,581 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-21 11:37:41,581 - algorithms.BertTrain - INFO - Run   2858    10      7073     7/643         1% 317.335411 42.467529       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 317.3354107141495\u001b[0m\n",
      "\u001b[31m###score: val_loss### 42.46752882003784\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:41:53,006 - algorithms.BertTrain - INFO - Train set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:41:53,014 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_0956120c-5024-43b5-af50-838019775fce_20191021_114153.csv: \u001b[0m\n",
      "\u001b[31m[[4258    0]\n",
      " [ 884    0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:41:53,020 - algorithms.BertTrain - INFO - Train set result details: 0.0\u001b[0m\n",
      "\u001b[31m2019-10-21 11:41:53,020 - algorithms.BertTrain - INFO - Validation set result details:\u001b[0m\n",
      "\u001b[31m2019-10-21 11:42:00,924 - algorithms.result_writer - INFO - Confusion matrix, full output in /opt/ml/output/data/predictedvsactual_b8c3b70b-5c56-41e0-b9cc-d7d1adbc9d30_20191021_114200.csv: \u001b[0m\n",
      "\u001b[31m[[576   0]\n",
      " [116   0]]\u001b[0m\n",
      "\u001b[31m2019-10-21 11:42:00,926 - algorithms.BertTrain - INFO - Validation set result details: 0.0 \u001b[0m\n",
      "\u001b[31m2019-10-21 11:42:00,926 - algorithms.BertTrain - INFO - Run   3117    11      7716     7/643         1% 304.146462 40.741266       0.0000       0.0000\u001b[0m\n",
      "\u001b[31m###score: train_loss### 304.1464619934559\u001b[0m\n",
      "\u001b[31m###score: val_loss### 40.74126574397087\u001b[0m\n",
      "\u001b[31m###score: train_fscore### 0.0\u001b[0m\n",
      "\u001b[31m###score: val_fscore### 0.0\u001b[0m\n"
     ]
    },
    {
     "ename": "EndpointConnectionError",
     "evalue": "Could not connect to the endpoint URL: \"https://api.sagemaker.us-east-2.amazonaws.com/\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 141\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/httpsession.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    638\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 639\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    640\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Disabled, indicate to re-raise the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 150\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <botocore.awsrequest.AWSHTTPSConnection object at 0x113eace10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEndpointConnectionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0731e612c7b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \"\"\"\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   1477\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_describe_job_call\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m                 \u001b[0mlast_describe_job_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             http, parsed_response = self._make_request(\n\u001b[0;32m--> 648\u001b[0;31m                 operation_model, request_dict, request_context)\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         self.meta.events.emit(\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, operation_model, request_dict, request_context)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             self.meta.events.emit(\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36mmake_request\u001b[0;34m(self, operation_model, request_dict)\u001b[0m\n\u001b[1;32m    100\u001b[0m         logger.debug(\"Making request for %s with params: %s\",\n\u001b[1;32m    101\u001b[0m                      operation_model, request_dict)\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, request_dict, operation_model)\u001b[0m\n\u001b[1;32m    135\u001b[0m             request, operation_model, context)\n\u001b[1;32m    136\u001b[0m         while self._needs_retry(attempts, operation_model, request_dict,\n\u001b[0;32m--> 137\u001b[0;31m                                 success_response, exception):\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mattempts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# If there is a stream associated with the request, we need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_needs_retry\u001b[0;34m(self, attempts, operation_model, request_dict, response, caught_exception)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0moperation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattempts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             caught_exception=caught_exception, request_dict=request_dict)\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mhandler_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_non_none_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandler_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/hooks.py\u001b[0m in \u001b[0;36memit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0maliased_event_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_event_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_emitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maliased_event_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit_until_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/hooks.py\u001b[0m in \u001b[0;36memit\u001b[0;34m(self, event_name, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m                  \u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_emit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit_until_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/hooks.py\u001b[0m in \u001b[0;36m_emit\u001b[0;34m(self, event_name, kwargs, stop_on_response)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers_to_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Event %s: calling handler %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0mresponses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_on_response\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, attempts, response, caught_exception, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \"\"\"\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaught_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattempts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retry needed, action of: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempt_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaught_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         should_retry = self._should_retry(attempt_number, response,\n\u001b[0;32m--> 251\u001b[0;31m                                           caught_exception)\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshould_retry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattempt_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_attempts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m_should_retry\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# If we've exceeded the max attempts we just let the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;31m# propogate if one has occurred.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattempt_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaught_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchecker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             checker_response = checker(attempt_number, response,\n\u001b[0;32m--> 317\u001b[0;31m                                        caught_exception)\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchecker_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mchecker_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, attempt_number, response, caught_exception)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcaught_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             return self._check_caught_exception(\n\u001b[0;32m--> 223\u001b[0;31m                 attempt_number, caught_exception)\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Both response and caught_exception are None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/retryhandler.py\u001b[0m in \u001b[0;36m_check_caught_exception\u001b[0;34m(self, attempt_number, caught_exception)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the MaxAttemptsDecorator is not interested in retrying the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# then this exception just propogates out past the retry code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mcaught_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_do_get_response\u001b[0;34m(self, request, operation_model)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mhttp_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_non_none_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhttp_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0mhttp_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPClientError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/untitled2/lib/python3.6/site-packages/botocore/httpsession.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNewConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaierror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEndpointConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mProxyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mProxyConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxy_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEndpointConnectionError\u001b[0m: Could not connect to the endpoint URL: \"https://api.sagemaker.us-east-2.amazonaws.com/\""
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
